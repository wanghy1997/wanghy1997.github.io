import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,e as o,b as r,o as n}from"./app-BSlDOcH0.js";const i={};function p(s,e){return n(),t("div",null,[o(" markdownlint-disable MD033 "),e[0]||(e[0]=r('<p><a href="https://www.langchain.asia/" target="_blank" rel="noopener noreferrer">https://www.langchain.asia/</a></p><p><a href="https://www.cnblogs.com/AlwaysSui/p/18144181" target="_blank" rel="noopener noreferrer">https://www.cnblogs.com/AlwaysSui/p/18144181</a></p><h2 id="复杂推理" tabindex="-1"><a class="header-anchor" href="#复杂推理"><span>复杂推理</span></a></h2><p>复杂推理：大语言模型的北极星能力<br><a href="https://github.com/FranxYao/chain-of-thought-hub" target="_blank" rel="noopener noreferrer">https://github.com/FranxYao/chain-of-thought-hub</a></p><p><a href="https://yaofu.notion.site/6dafe3f8d11445ca9dcf8a2ca1c5b199" target="_blank" rel="noopener noreferrer">中文</a></p><p><a href="https://yaofu.notion.site/Towards-Complex-Reasoning-the-Polaris-of-Large-Language-Models-c2b4a51355b44764975f88e6a42d4e75" target="_blank" rel="noopener noreferrer">https://yaofu.notion.site/Towards-Complex-Reasoning-the-Polaris-of-Large-Language-Models-c2b4a51355b44764975f88e6a42d4e75</a></p><h2 id="cot" tabindex="-1"><a class="header-anchor" href="#cot"><span>CoT</span></a></h2><p>AUTOMATIC CHAIN OF THOUGHT PROMPTING IN LARGE LANGUAGE MODELS ()</p><p>Large Language Models Are Zero-Shot Reasoners （NeurIPS 2022）</p><p>Complexity-Based Prompting For Multi-Step Reasoning （ICLR 2022）</p><p>Automatic Chain Of Thought Prompting In Large Language Models （ICLR 2023）</p><p>Auto-CoT: Automatic Chain of Thought Prompting in Large Language Models (ICLR 2023)<br><a href="https://github.com/amazon-science/auto-cot" target="_blank" rel="noopener noreferrer">https://github.com/amazon-science/auto-cot</a></p><h2 id="类比提示-analogical-prompting" tabindex="-1"><a class="header-anchor" href="#类比提示-analogical-prompting"><span>&quot;类比提示&quot;(analogical prompting)</span></a></h2><ul><li><p><strong>Emergent Analogical Reasoning in Large Language Models</strong> <br><br><small> (NHB&#39;23, Nature Human Behaviour 2023) @University of California </small><br><a href="https://www.nature.com/articles/s41562-023-01659-w" target="_blank" rel="noopener noreferrer">[Paper]</a><br><a href="https://arxiv.org/pdf/2212.09196" target="_blank" rel="noopener noreferrer">[arXiv]</a><br><a href="https://github.com/taylorwwebb/emergent_analogies_LLM" target="_blank" rel="noopener noreferrer">[Code]</a></p></li><li><p><strong>LARGE LANGUAGE MODELS AS ANALOGICAL REASONERS</strong> <br><br><small> (ICLR&#39;24) @Google DeepMind </small><br><a href="https://arxiv.org/abs/2310.01714" target="_blank" rel="noopener noreferrer">[arXiv]</a><br><a href="https://mp.weixin.qq.com/s/EcOMx7FCE-oiE0_4OqC1bA" target="_blank" rel="noopener noreferrer">[推文]</a></p></li></ul>',14))])}const c=a(i,[["render",p]]),g=JSON.parse(`{"path":"/discover/uncover/CoT.html","title":"ICL/CoT/GoT","lang":"en-US","frontmatter":{"title":"ICL/CoT/GoT","description":"https://www.langchain.asia/ https://www.cnblogs.com/AlwaysSui/p/18144181 复杂推理 复杂推理：大语言模型的北极星能力 https://github.com/FranxYao/chain-of-thought-hub 中文 https://yaofu.notion.site/Towa...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"ICL/CoT/GoT\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-09-17T15:06:21.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Hongyi Wang\\",\\"url\\":\\"https://wanghy1997.github.io/wanghy1997\\"}]}"],["meta",{"property":"og:url","content":"https://wanghy1997.github.io/wanghy1997/discover/uncover/CoT.html"}],["meta",{"property":"og:site_name","content":"Hongyi's Blog"}],["meta",{"property":"og:title","content":"ICL/CoT/GoT"}],["meta",{"property":"og:description","content":"https://www.langchain.asia/ https://www.cnblogs.com/AlwaysSui/p/18144181 复杂推理 复杂推理：大语言模型的北极星能力 https://github.com/FranxYao/chain-of-thought-hub 中文 https://yaofu.notion.site/Towa..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-09-17T15:06:21.000Z"}],["meta",{"property":"article:modified_time","content":"2025-09-17T15:06:21.000Z"}]]},"git":{"createdTime":1758121581000,"updatedTime":1758121581000,"contributors":[{"name":"whymbp","username":"whymbp","email":"why_6267@163.com","commits":1,"url":"https://github.com/whymbp"}]},"readingTime":{"minutes":0.54,"words":162},"filePathRelative":"discover/uncover/CoT.md","excerpt":"<!-- markdownlint-disable MD033 -->\\n<p><a href=\\"https://www.langchain.asia/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://www.langchain.asia/</a></p>\\n<p><a href=\\"https://www.cnblogs.com/AlwaysSui/p/18144181\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://www.cnblogs.com/AlwaysSui/p/18144181</a></p>","autoDesc":true}`);export{c as comp,g as data};
